{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- To identify bearish candlestick vs bullish candlestick, see:\n",
    "-- https://en.wikipedia.org/wiki/Candlestick_pattern#Formation_of_candlestick\n",
    "\n",
    "-- Task 1 \n",
    "-- Find Hammer pattern\n",
    "\n",
    "SELECT d1.*\n",
    "FROM daily_ohlc d1\n",
    "JOIN daily_ohlc d0 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close < d0.open  -- Previous day is bearish\n",
    "    AND d1.close > d1.open  -- Current day is bullish\n",
    "    AND d1.high = d1.close;  -- High price is the close price\n",
    "\n",
    "-- Find Inverted Hammer pattern\n",
    "\n",
    "SELECT d1.*\n",
    "FROM daily_ohlc d1\n",
    "JOIN daily_ohlc d0 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close < d0.open  -- Previous day is bearish\n",
    "    AND d1.close > d1.open  -- Current day is bullish\n",
    "    AND d1.low = d1.open;  -- Low price is the open price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Task 2 \n",
    "-- Find Engulfing Bullish pattern\n",
    "-- INSERT INTO engulfing_bullish_patterns (day, open, high, low, close, volume)\n",
    "SELECT d1.*\n",
    "FROM daily_ohlc d0\n",
    "JOIN daily_ohlc d1 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close < d0.open  -- Previous day is bearish\n",
    "    AND d1.close > d1.open  -- Current day is bullish\n",
    "    AND d1.open < d0.close  -- The bullish candle opens lower\n",
    "    AND d1.close > d0.open; -- The bullish candle fully engulfs the bearish one\n",
    "\n",
    "\n",
    "-- Find Piercing Line pattern\n",
    "-- INSERT INTO piercing_line_patterns (day, open, high, low, close, volume)\n",
    "SELECT d1.*\n",
    "FROM daily_ohlc d0\n",
    "JOIN daily_ohlc d1 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close < d0.open  -- Previous day is bearish\n",
    "    AND d1.close > d1.open  -- Current day is bullish\n",
    "    AND d1.open < d0.low  -- Bullish candle opens lower than previous low\n",
    "    AND d1.close > (d0.open + d0.close) / 2; -- Closes more than halfway into bearish candle\n",
    "\n",
    "\n",
    "-- Find Morning Star pattern\n",
    "-- INSERT INTO morning_star_patterns (day, open, high, low, close, volume)\n",
    "SELECT d2.*\n",
    "FROM daily_ohlc d0\n",
    "JOIN daily_ohlc d1 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "JOIN daily_ohlc d2 ON d2.day = d1.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close < d0.open  -- First day is bearish\n",
    "    -- Gabriel's interpretation:\n",
    "    AND d1.close BETWEEN d0.low AND d0.close  -- Second day is a small candle below first day\n",
    "    -- Stefan's interpretation:\n",
    "    -- AND d1.open < d0.close -- Second day's candlestick body is entirely below the first day's candlestick body\n",
    "    -- AND d1.close < d0.close\n",
    "    AND d2.close > d2.open  -- Third day is bullish\n",
    "    AND d2.close > (d0.open + d0.close) / 2; -- Third day's close overlaps the first day's body\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Task 2 Calculate average number of continuously bullish days following each pattern\n",
    "-- (e.g., hammer, inverted hammer, morning star) + check how reliable each pattern is\n",
    "-- at predicting the future stock prices\n",
    "\n",
    "-- To simplify the data processing process, we should save the pattern data collected\n",
    "-- from previous tasks into a table\n",
    "-- E.g., prepend the previous sql statements with:\n",
    "-- INSERT INTO hammer_patterns (day, open, high, low, close, volume)\n",
    "-- INSERT INTO inverted_hammer_patterns (day, open, high, low, close, volume)\n",
    "-- INSERT INTO morning_star_patterns (day, open, high, low, close, volume)\n",
    "\n",
    "-- For Stefan's interpretation of \"number of continuously bullish days following each pattern\",\n",
    "-- see `number_of_consecutive_bullish_days.sql`\n",
    "\n",
    "WITH bullish_streaks AS (\n",
    "    SELECT p.day, COUNT(*) AS bullish_days\n",
    "    FROM (\n",
    "        SELECT t1.day, COUNT(*) OVER (PARTITION BY t1.day ORDER BY t2.day) AS bullish_days\n",
    "        FROM daily_ohlc t1\n",
    "        LEFT JOIN daily_ohlc t2 ON t2.day > t1.day\n",
    "        WHERE t2.close > t2.open\n",
    "    ) as p\n",
    "    GROUP BY p.day\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    pattern, \n",
    "    AVG(bullish_days) AS avg_bullish_streak,\n",
    "    COUNT(*) AS total_occurrences,\n",
    "    SUM(CASE WHEN bullish_days >= 2 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS reliability_percentage\n",
    "FROM (\n",
    "    SELECT 'Engulfing Bullish' AS pattern, day FROM engulfing_bullish_patterns\n",
    "    UNION ALL\n",
    "    SELECT 'Piercing Line', day FROM piercing_line_patterns\n",
    "    UNION ALL\n",
    "    SELECT 'Morning Star', day FROM morning_star_patterns\n",
    ") patterns\n",
    "JOIN bullish_streaks ON patterns.day = bullish_streaks.day\n",
    "GROUP BY pattern;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Task 3\n",
    "\n",
    "-- Find Engulfing bearish pattern (simply the opposite of Engulfing bullish pattern)\n",
    "-- INSERT INTO engulfing_bearish_patterns (day, open, high, low, close, volume)\n",
    "SELECT d1.*\n",
    "FROM daily_ohlc d0\n",
    "JOIN daily_ohlc d1 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close > d0.open  -- First day is bullish\n",
    "    AND d1.close < d1.open  -- Second day is bearish\n",
    "    AND d1.open > d0.close  -- Second day opens above first day's close\n",
    "    AND d1.close < d0.open; -- Second day's close is lower than first day's open\n",
    "\n",
    "\n",
    "-- Find Evening star pattern (simply the opposite of star pattern)\n",
    "-- INSERT INTO evening_star_patterns (day, open, high, low, close, volume)\n",
    "SELECT d2.*\n",
    "FROM daily_ohlc d0\n",
    "JOIN daily_ohlc d1 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "JOIN daily_ohlc d2 ON d2.day = d1.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close > d0.open  -- First day is bullish\n",
    "    AND d1.close BETWEEN d0.low AND d0.high  -- Second day is a small candle\n",
    "    AND d2.close < d2.open  -- Third day is bearish\n",
    "    AND d2.close < (d0.open + d0.close) / 2; -- Third day's close is below first day's midpoint\n",
    "\n",
    "\n",
    "-- Find Three white soldier patterns\n",
    "-- INSERT INTO three_white_soldiers_patterns (day, open, high, low, close, volume)\n",
    "SELECT d2.*\n",
    "FROM daily_ohlc d0\n",
    "JOIN daily_ohlc d1 ON d1.day = d0.day + INTERVAL '1 day'\n",
    "JOIN daily_ohlc d2 ON d2.day = d1.day + INTERVAL '1 day'\n",
    "WHERE \n",
    "    d0.close > d0.open  -- First day is bullish\n",
    "    AND d1.open BETWEEN d0.open AND d0.close  -- Second day opens within first day\n",
    "    AND d1.close > d0.close  -- Second day closes higher\n",
    "    AND d1.close > d1.open  -- Second day is bullish\n",
    "    AND d2.open BETWEEN d1.open AND d1.close  -- Third day opens within second day\n",
    "    AND d2.close > d1.close  -- Third day closes higher\n",
    "    AND d2.close > d2.open; -- Third day is bullish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Optimisation for performance:\n",
    "\n",
    "#### Query based improvements\n",
    "\n",
    "1) Materialized View Definitions\n",
    "A continuous aggregate in TimescaleDB is a materialized view that automatically refreshes and stores aggregated results efficiently over time.\n",
    "Speeds up queries that use GROUP BY (e.g., OHLC calculations).\n",
    "\n",
    "\n",
    "2) Leverage timescales specific query (hyperfunctions)\n",
    "last(close, day)\n",
    "first(open, day)\n",
    "\n",
    "CREATE MATERIALIZED VIEW daily_ohlc_cagg\n",
    "WITH (timescaledb.continuous) AS\n",
    "SELECT \n",
    "    time_bucket('1 day', day) AS day,\n",
    "    first(open, day) AS open,\n",
    "    MAX(high) AS high,\n",
    "    MIN(low) AS low,\n",
    "    last(close, day) AS close,\n",
    "    SUM(volume) AS volume\n",
    "FROM daily_ohlc\n",
    "GROUP BY day;\n",
    "\n",
    "3) SQL Scripts: For creating indexes. Place discrete columns first in created indexes, then continuous columns\n",
    "\n",
    "CREATE INDEX ON daily_ohlc_cagg (day DESC);\n",
    "CREATE INDEX ON engulfing_bearish_patterns (day DESC);\n",
    "CREATE INDEX ON evening_star_patterns (day DESC);\n",
    "CREATE INDEX ON three_white_soldiers_patterns (day DESC);\n",
    "\n",
    "----------------------------------------------------------------\n",
    "CREATE INDEX ON daily_ohlc_cagg (day DESC, close, open);\n",
    "CREATE INDEX ON daily_ohlc_cagg (day DESC, open, close);\n",
    "\n",
    "#### Database based improvements\n",
    "\n",
    "4) timescaledb-tune - memory (not really disk) (postgresql.conf)\n",
    "\n",
    "#### Memory based improvements\n",
    "\n",
    "5) schema improvements to reduce memory usage\n",
    "\n",
    "avoid numeric data types, use int with max 2 dp. Stocks priced above $1 or penny stocks are typically quoted to 2 decimal places (https://www.investopedia.com/terms/t/tick.asp) (use smallint a range of -32,768 to +32,767 2bytes)\n",
    "The storage requirement for a numeric value in PostgreSQL is two bytes for each group of four decimal digits, plus three to eight bytes of overhead.\n",
    "For 24.98437:\n",
    "\n",
    "Total digits: 7\n",
    "\n",
    "Groups of four digits: 2 (2498 and 4370)\n",
    "\n",
    "Storage: (2 * 2) + 3 to 8 bytes overhead\n",
    "\n",
    "Total: 7 to 12 bytes\n",
    "\n",
    "6) set_chunk_time_interval to define chunks that make up no more than 25% of main memory (across all hyper tables) 25% is the size of shared buffers \n",
    "shared_buffer = 25% of RAM.\n",
    "\n",
    "\n",
    "#### More tuning\n",
    "7) Background workers\n",
    "Background workers perform background processing for operations specific to TimescaleDB (both live queries and background jobs, all kinds of User-Defined Actions/Policies).\n",
    "\n",
    "The background worker's settings need to be tuned to get the most out of TimescaleDBâ€”issues often arise when worker settings are not properly set. Some of the issues we see often caused by a misconfiguration of background workers are:\n",
    "User-Defined Actions are not working properly.\n",
    "Continuous aggregates are not working properly.\n",
    "Compression policies are not working properly.\n",
    "The retention policies are not working properly.\n",
    "Database size rapidly increases, due to failures in compression and the data retention policies.\n",
    "\n",
    "- You should configure the timescaledb.max_background_workers setting to be equal to the sum of your total number of databases + the total number of concurrent background workers you want running at any given point in time.\n",
    "- By default, the max_parallel_workers setting corresponds to the number of CPUs available.\n",
    "- max_worker_processes should be AT LEAST 3 (required for checkpointer, WAL writer, and vacuum processes) plus the sum of the background workers and parallel workers:\n",
    "max_worker_processes = 3 + timescaledb.max_background_workers + max_parallel_workers.\n",
    "\n",
    "\n",
    "https://www.timescale.com/blog/timescale-parameters-you-should-know-about-and-tune-to-maximize-your-performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
